#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í•œêµ­ì–´ ìŒì„± ì¸ì‹ ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ - Phase 2-2.6-Conservative
GPU OOM ê³ ë ¤í•œ í˜„ì‹¤ì  ê°œì„  - Step 1 (ì•ˆì „ ìš°ì„ )
"""

import os
import json
import pandas as pd
import numpy as np
import torch
import librosa
import re
from datetime import datetime
from datasets import Dataset, Audio
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Trainer, TrainingArguments, TrainerCallback
from transformers import get_cosine_schedule_with_warmup
from dataclasses import dataclass
from typing import Dict, List, Union
import matplotlib.pyplot as plt

# ğŸ”§ ë°ë“œë½ í•´ê²° ì„¤ì •
os.environ["NCCL_P2P_DISABLE"] = "1"  # ğŸš¨ í•µì‹¬: NCCL P2P ë¹„í™œì„±í™”
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # Single GPU ê°•ì œ ì‚¬ìš©
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

def main():
    print("=== ğŸš€ Phase 2-2.6-Conservative: GPU OOM ê³ ë ¤í•œ í˜„ì‹¤ì  ê°œì„  ===")
    print("ğŸ”§ Step 1: ì•ˆì „ ìš°ì„  + ì ì§„ì  ë ˆì´ì–´ í•´ì œ + ì•ˆì •ì  í•™ìŠµë¥ ")
    
    # GPU ì„¤ì • í™•ì¸
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")
    if torch.cuda.is_available():
        print(f"í˜„ì¬ GPU: {torch.cuda.current_device()}")
        print(f"GPU ì´ë¦„: {torch.cuda.get_device_name()}")
    
    # ===== 1. ë°ì´í„° ë¡œë”© =====
    print("\n1. ë°ì´í„° ë¡œë”©...")
    
    train_audio_dir = "../../data/train/audio"
    train_json_dir = "../../data/train/label"
    valid_audio_dir = "../../data/valid/audio" 
    valid_json_dir = "../../data/valid/label"
    
    def load_json_files(directory):
        json_data = []
        for root, dirs, files in os.walk(directory):
            for filename in files:
                if filename.endswith('.json'):
                    with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        json_data.append(data)
        return json_data
    
    def create_dataframe(json_data, audio_base_dir):
        data = []
        for item in json_data:
            file_name = item.get('fileName')
            answer_text = item.get('transcription', {}).get('AnswerLabelText', '')
            
            if file_name and answer_text:
                audio_path = None
                for root, dirs, files in os.walk(audio_base_dir):
                    if file_name in files:
                        audio_path = os.path.join(root, file_name)
                        break
                
                if audio_path and os.path.exists(audio_path):
                    data.append({
                        'file_path': audio_path,
                        'text': answer_text
                    })
        
        return pd.DataFrame(data)
    
    train_json = load_json_files(train_json_dir)
    valid_json = load_json_files(valid_json_dir)
    
    train_df = create_dataframe(train_json, train_audio_dir)
    valid_df = create_dataframe(valid_json, valid_audio_dir)
    
    print(f"ğŸ”§ Phase 2-2.6-Conservative: ì „ì²´ ë°ì´í„° ì‚¬ìš© - í•™ìŠµ: {len(train_df)}ê°œ, ê²€ì¦: {len(valid_df)}ê°œ")
    
    # í…ìŠ¤íŠ¸ ì •ê·œí™”
    def prepare_korean_text(text):
        text = re.sub(r'[^\uAC00-\uD7A3\s.,!?]', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    
    train_df['normalized_text'] = train_df['text'].apply(prepare_korean_text)
    valid_df['normalized_text'] = valid_df['text'].apply(prepare_korean_text)
    
    print(f"ìµœì¢… ë°ì´í„° í¬ê¸° - í•™ìŠµ: {len(train_df)}, ê²€ì¦: {len(valid_df)}")
    
    # ===== 2. ëª¨ë¸ ë¡œë”© =====
    print("\n2. ëª¨ë¸ ë¡œë”©...")
    
    MODEL_ID = "kresnik/wav2vec2-large-xlsr-korean"
    processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)
    
    model = Wav2Vec2ForCTC.from_pretrained(
        MODEL_ID,
        ctc_loss_reduction="mean",
        pad_token_id=processor.tokenizer.pad_token_id,
        gradient_checkpointing=True,  # ğŸ”§ ë©”ëª¨ë¦¬ ìµœì í™” ì¶”ê°€
        low_cpu_mem_usage=True,
    )
    
    # ğŸ”§ Phase 2-2.6-Conservative: Feature encoderë§Œ ê³ ì • (combine.ipynb ë°©ì‹)
    model.freeze_feature_encoder()
    print("âœ… Feature Encoderë§Œ ê³ ì •ë¨ (ì ì§„ì  í•´ì œ ì˜ˆì •)")
    
    # ğŸ”§ Single GPU ê°•ì œ ì„¤ì •
    if torch.cuda.is_available():
        model = model.to("cuda:0")
    
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (Feature Encoderë§Œ ê³ ì •, Single GPU)")
    
    # ===== 3. ë°ì´í„°ì…‹ ì¤€ë¹„ =====
    print("\n3. ë°ì´í„°ì…‹ ì¤€ë¹„...")
    
    def prepare_dataset(df):
        dataset = Dataset.from_pandas(df)
        dataset = dataset.cast_column("file_path", Audio(sampling_rate=16000))
        return dataset
    
    train_dataset = prepare_dataset(train_df)
    valid_dataset = prepare_dataset(valid_df)
    
    def prepare_dataset_for_model_safe(batch):
        audio = batch["file_path"]
        array = audio["array"]
        
        # ğŸ”§ 15ì´ˆ ì˜¤ë””ì˜¤ ìœ ì§€
        max_samples = 15 * 16000
        if len(array) > max_samples:
            array = array[:max_samples]
        
        if np.max(np.abs(array)) > 0:
            array = array / np.max(np.abs(array))
        
        batch["input_values"] = processor(
            array, 
            sampling_rate=16000,
            max_length=max_samples,
            truncation=True,
            padding=False
        ).input_values[0]
        
        with processor.as_target_processor():
            batch["labels"] = processor(batch["normalized_text"]).input_ids
        
        return batch
    
    print("ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì¤‘...")
    train_dataset = train_dataset.map(prepare_dataset_for_model_safe, remove_columns=train_dataset.column_names)
    valid_dataset = valid_dataset.map(prepare_dataset_for_model_safe, remove_columns=valid_dataset.column_names)
    
    # 15ì´ˆ í•„í„°ë§
    def filter_15sec(example):
        audio_length = len(example["input_values"])
        return 1*16000 <= audio_length <= 15*16000
    
    train_dataset = train_dataset.filter(filter_15sec)
    valid_dataset = valid_dataset.filter(filter_15sec)
    
    print(f"15ì´ˆ í•„í„°ë§ í›„ - í•™ìŠµ: {len(train_dataset)}, ê²€ì¦: {len(valid_dataset)}")
    
    # ===== 4. ë°ì´í„° ì½œë ˆì´í„° =====
    @dataclass
    class DataCollatorCTCSafe:
        processor: Wav2Vec2Processor
        padding: Union[bool, str] = True

        def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
            input_features = [{"input_values": feature["input_values"]} for feature in features]
            label_features = [{"input_ids": feature["labels"]} for feature in features]

            batch = self.processor.pad(input_features, padding=self.padding, return_tensors="pt")
            
            with self.processor.as_target_processor():
                labels_batch = self.processor.pad(label_features, padding=self.padding, return_tensors="pt")

            batch["labels"] = labels_batch["input_ids"]
            return batch
    
    data_collator = DataCollatorCTCSafe(processor=processor)
    
    # ===== 5. í‰ê°€ ë©”íŠ¸ë¦­ =====
    def compute_metrics_safe(pred):
        try:
            import evaluate
            wer_metric = evaluate.load("wer")
            
            pred_logits = pred.predictions
            pred_ids = np.argmax(pred_logits, axis=-1)
            pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id
            
            pred_str = processor.batch_decode(pred_ids)
            label_str = processor.batch_decode(pred.label_ids, group_tokens=False)
            
            wer = wer_metric.compute(predictions=pred_str, references=label_str)
            return {"wer": wer}
        except Exception as e:
            print(f"ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    # ===== 6. Phase 2-2.6-Conservative: ìŠ¤ë§ˆíŠ¸ ì–¸í”„ë¦¬ì¦ˆ ì½œë°± =====
    class SmartUnfreezeCallback(TrainerCallback):
        """combine.ipynb ë°©ì‹ì˜ ì ì§„ì  ë ˆì´ì–´ í•´ì œ"""
        
        def on_epoch_begin(self, args, state, control, **kwargs):
            model = kwargs.get('model', None)
            if model is None:
                return
                
            if state.epoch == 5:
                # Feature encoderë§Œ í•´ì œ (combine.ipynb ë°©ì‹)
                model.wav2vec2.feature_extractor._freeze_parameters = False
                for param in model.wav2vec2.feature_extractor.parameters():
                    param.requires_grad = True
                print("ğŸ”“ Feature Encoder í•´ì œë¨ (5 ì—í¬í¬)")
            elif state.epoch == 8:
                # Conservativeì—ì„œëŠ” 8 ì—í¬í¬ì—ì„œ ìƒìœ„ 2ê°œ Transformer ë ˆì´ì–´ë§Œ ì¶”ê°€ í•´ì œ
                for layer in model.wav2vec2.encoder.layers[-2:]:
                    for param in layer.parameters():
                        param.requires_grad = True
                print("ğŸ”“ ìƒìœ„ 2ê°œ Transformer ë ˆì´ì–´ í•´ì œë¨ (8 ì—í¬í¬)")
        
        def on_epoch_end(self, args, state, control, **kwargs):
            # ì—í¬í¬ ëì— GPU ìºì‹œ ì •ë¦¬
            torch.cuda.empty_cache()
            print(f"ğŸ§¹ ì—í¬í¬ {state.epoch} ì™„ë£Œ, GPU ìºì‹œ ì •ë¦¬ë¨")
    
    # ===== 7. Phase 2-2.6-Conservative: ê°„ë‹¨í•œ Early Stopping =====
    class SimpleEarlyStoppingCallback(TrainerCallback):
        """ë²„ê·¸ ìˆ˜ì •ëœ ê°„ë‹¨í•œ Early Stopping"""
        
        def __init__(self, patience=3):
            self.patience = patience
            self.best_wer = float('inf')
            self.wait = 0
            
        def on_evaluate(self, args, state, control, logs=None, **kwargs):
            if logs is None:
                return
                
            current_wer = logs.get('eval_wer', float('inf'))
            
            if current_wer < self.best_wer:
                self.best_wer = current_wer
                self.wait = 0
                print(f"ğŸ¯ ìƒˆë¡œìš´ ìµœê³  WER: {current_wer:.4f}")
                
                # Phase 2-2.6 ëª©í‘œ í™•ì¸
                if current_wer < 0.55:
                    print(f"ğŸ‰ Phase 2-2.6-Conservative 1ì°¨ ëª©í‘œ ë‹¬ì„±! WER {current_wer:.4f} < 0.55")
                if current_wer < 0.50:
                    print(f"ğŸ‰ Phase 2-2.6-Conservative 2ì°¨ ëª©í‘œ ë‹¬ì„±! WER {current_wer:.4f} < 0.50")
            else:
                self.wait += 1
                print(f"â³ Early stopping: {self.wait}/{self.patience}")
                
            if self.wait >= self.patience:
                control.should_training_stop = True
                print("â¹ï¸ Early stopping í™œì„±í™”")
        
        def on_train_end(self, args, state, control, **kwargs):
            print(f"ğŸ“Š í•™ìŠµ ì™„ë£Œ - ìµœê³  WER: {self.best_wer:.4f}")
    
    # ===== 8. íŠ¸ë ˆì´ë„ˆ ì„¤ì • =====
    print("\n8. Phase 2-2.6-Conservative íŠ¸ë ˆì´ë„ˆ ì„¤ì •...")
    
    training_args = TrainingArguments(
        output_dir="./wav2vec2-phase2-2-6-conservative",
        # ğŸ”§ ë©”ëª¨ë¦¬ ì•ˆì „ ì„¤ì •
        per_device_train_batch_size=2,      # ìœ ì§€ (OOM ë°©ì§€)
        per_device_eval_batch_size=2,       # ìœ ì§€
        gradient_accumulation_steps=4,      # 1 â†’ 4 (ìœ íš¨ ë°°ì¹˜: 8)
        
        # ğŸ”§ í•™ìŠµ ê¸°ê°„ í˜„ì‹¤ì  ì¡°ì •
        num_train_epochs=8,                 # Conservative: 8 ì—í¬í¬
        max_steps=2000,                     # ì•ˆì „ì¥ì¹˜
        
        # ğŸ”§ í‰ê°€ ë° ì €ì¥ ì£¼ê¸°
        eval_strategy="steps",
        eval_steps=100,                     # ë” ìì£¼ ëª¨ë‹ˆí„°ë§
        save_steps=200,                     # ì²´í¬í¬ì¸íŠ¸ ë¹ˆë„ ì¦ê°€
        logging_steps=50,
        
        # ğŸ”§ ì•ˆì •ì  í•™ìŠµë¥  ì „ëµ
        learning_rate=3e-4,                 # combine.ipynbì™€ ë™ì¼
        lr_scheduler_type="constant",       # ìŠ¤ì¼€ì¤„ë§ ì œê±°
        warmup_steps=100,                   # ìµœì†Œí•œì˜ warmup
        weight_decay=0.005,                 # ìœ ì§€
        
        # ğŸ”§ ë©”ëª¨ë¦¬ ìµœì í™”
        fp16=True,
        dataloader_pin_memory=False,
        dataloader_num_workers=0,
        
        # ğŸ”§ ê¸°íƒ€ ì„¤ì •
        save_total_limit=3,
        load_best_model_at_end=True,
        metric_for_best_model="wer",
        greater_is_better=False,
        report_to=None,
        disable_tqdm=False,
        group_by_length=False,
        no_cuda=False,
        local_rank=-1,
        ddp_find_unused_parameters=False,
    )
    
    # ===== 9. ì½œë°± ì„¤ì • =====
    smart_unfreeze_callback = SmartUnfreezeCallback()
    early_stopping_callback = SimpleEarlyStoppingCallback(patience=3)
    
    trainer = Trainer(
        model=model,
        args=training_args,
        data_collator=data_collator,
        compute_metrics=compute_metrics_safe,
        train_dataset=train_dataset,
        eval_dataset=valid_dataset,
        tokenizer=processor,
        callbacks=[smart_unfreeze_callback, early_stopping_callback]
    )
    
    print("âœ… Phase 2-2.6-Conservative íŠ¸ë ˆì´ë„ˆ ì„¤ì • ì™„ë£Œ")
    print(f"ğŸ”§ Conservative ì„¤ì •:")
    print(f"  - ë ˆì´ì–´ ê³ ì •: Feature encoderë§Œ (5 ì—í¬í¬ í›„ í•´ì œ)")
    print(f"  - ì—í¬í¬ ìˆ˜: 8 (ì•ˆì „ ìš°ì„ )")
    print(f"  - Gradient accumulation: 4 (ìœ íš¨ ë°°ì¹˜: 8)")
    print(f"  - í•™ìŠµë¥ : 3e-4 (ê³ ì •, ìŠ¤ì¼€ì¤„ë§ ì—†ìŒ)")
    print(f"  - Early Stopping: 3 patience")
    print(f"  - ëª©í‘œ: WER < 0.55 (1ì°¨), WER < 0.50 (2ì°¨)")
    
    # ===== 10. ì•ˆì „í•œ í•™ìŠµ ì‹œì‘ =====
    print("\n10. Phase 2-2.6-Conservative í•™ìŠµ ì‹œì‘...")
    
    start_time = datetime.now()
    print(f"ì‹œì‘ ì‹œê°„: {start_time}")
    
    try:
        trainer.train()
        
        end_time = datetime.now()
        duration = end_time - start_time
        print(f"\nâœ… Phase 2-2.6-Conservative í•™ìŠµ ì™„ë£Œ!")
        print(f"ì´ ì‹œê°„: {duration}")
        
        # ğŸ”§ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        model_save_path = "../../models/phase2-2-6-conservative-model"
        os.makedirs("../../models", exist_ok=True)
        
        model.save_pretrained(model_save_path)
        processor.save_pretrained(model_save_path)
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")
        
        # ìµœì¢… í‰ê°€
        eval_results = trainer.evaluate()
        final_wer = eval_results.get('eval_wer', 'N/A')
        best_wer = early_stopping_callback.best_wer
        
        print(f"ğŸ¯ ìµœì¢… WER: {final_wer:.4f}")
        print(f"ğŸ¯ ìµœê³  WER: {best_wer:.4f}")
        
        # Phase 2-2.6-Conservative ëª©í‘œ ë‹¬ì„± í™•ì¸
        if isinstance(best_wer, float):
            if best_wer < 0.50:
                print("ğŸ‰ Phase 2-2.6-Conservative 2ì°¨ ëª©í‘œ ë‹¬ì„±! WER < 0.50")
                print("âœ… Phase 2-2.6-Aggressive ì§„í–‰ ì¡°ê±´ ë§Œì¡±")
            elif best_wer < 0.55:
                print("ğŸ‰ Phase 2-2.6-Conservative 1ì°¨ ëª©í‘œ ë‹¬ì„±! WER < 0.55")
                print("âœ… ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰ ê°€ëŠ¥")
            else:
                print("âš ï¸ Phase 2-2.6-Conservative ëª©í‘œ ë¯¸ë‹¬ì„±")
                print("ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ë˜ëŠ” ë°ì´í„° ë¶„ì„ í•„ìš”")
            
            # ì´ì „ Phaseë“¤ê³¼ ë¹„êµ
            phase_2_1_wer = 0.6321
            phase_2_2_5_wer = 0.6092
            
            if best_wer < phase_2_1_wer:
                improvement_2_1 = ((phase_2_1_wer - best_wer) / phase_2_1_wer) * 100
                print(f"ğŸ“ˆ Phase 2-1 ëŒ€ë¹„ {improvement_2_1:.2f}% ê°œì„ ")
            
            if best_wer < phase_2_2_5_wer:
                improvement_2_2_5 = ((phase_2_2_5_wer - best_wer) / phase_2_2_5_wer) * 100
                print(f"ğŸ“ˆ Phase 2-2.5 ëŒ€ë¹„ {improvement_2_2_5:.2f}% ê°œì„ ")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n=== ğŸš€ Phase 2-2.6-Conservative ì‹¤í—˜ ì™„ë£Œ ===")

if __name__ == "__main__":
    main() 